{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "color-ivory",
   "metadata": {},
   "source": [
    "# Associations between molecular and environmental changes along the proximal-to-distal axis of the colon\n",
    "## Abstract\n",
    "### Objective\n",
    "Colorectal cancer is a heterogeneous disease, and tumours in the left or right sections of the colon are biologically disparate. The development of the two-colon paradigm, differentiating colorectal cancers according to their location relative to the splenic flexure, contributed to an improvement in prognosis and treatment. Recent studies challenged this division by proposing a continuum model where molecular properties follow a continuous trend along the colon. \n",
    "### Design\n",
    "We address the question of which model describes CRC properties better by comparing their performance in describing the properties of colorectal tumours in a cohort of 522 patients from The Cancer Genome Atlas.\n",
    "### Results\n",
    "Results show that no model outperforms the other. Alterations affecting genes associated with growth are described better by the two-colon paradigm, while the continuum colon model better approximates alterations affecting genes related to metabolism and environment. As this suggests an environmental impact on changes in selective constraints along the colon, we chart the localised metabolome in a cohort of 27 colon cancer patients. Metabolites follow a continuous trend in agreement with other tissue-environmental factors such as microbiome. We show that genes with continuous transcriptional profiles interact with metabolites associated with carcinogenesis, suggesting that gradients of metabolism-mediated selective constraints might contribute to gradual changes in tumours along the colon.\n",
    "### Conclusion\n",
    "Our results question the previous left/right model of colon cancer, suggesting that an increase in the resolution of tumour localisation might better capture the biology of tumours as systems interacting with their local environment and holding clinical relevance.\n",
    "### About this notebook\n",
    "This notebook allow to reproduce all the results and figures presented in [CITAZIONE] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-victor",
   "metadata": {},
   "source": [
    "# LOADING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "boolean-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../../../git/lib\") # Path to the profile_analysis_class.py lib\n",
    "sys.path.append(\"/home/ieo5417/Documenti/git/network_analysis/lib/\") # Path to the network_search_class.py lib\n",
    "from profile_analysis_class import ProfileAnalysis # Import the profile workflow class\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from supervenn import supervenn\n",
    "import mygene\n",
    "from scipy.stats import chi2_contingency\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import matplotlib\n",
    "import os\n",
    "import statistics\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import beta, norm\n",
    "\n",
    "from network_search_class import NetworkSearchAnalysis\n",
    "\n",
    "# Defining left and right sections\n",
    "left_sections = ['Descending colon','Sigmoid colon','Rectosigmoid junction','Rectum, NOS']\n",
    "right_sections = ['Cecum','Ascending colon','Hepatic flexure of colon','Transverse colon']\n",
    "\n",
    "mg = mygene.MyGeneInfo()\n",
    "plt.style.use('../../assets/styles/plotting_style.mplstyle') # Path to the matplotlib style sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organic-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dLR(data, left_sec = 'Sigmoid colon', right_sec = 'Transverse colon'):\n",
    "    # Create a dataframe with the selected section as right left sections\n",
    "    dLR = pd.DataFrame(index=data.index)\n",
    "    dLR['left']=data[{left_sec}]\n",
    "    dLR['right']=data[{right_sec}]\n",
    "    dLR['tcga_r/l']=dLR['right']/dLR['left']\n",
    "    return dLR\n",
    "\n",
    "def calculate_p(name, observable, background):\n",
    "    p_value = 1-stats.percentileofscore(background,observable)/100\n",
    "    return (name, p_value)\n",
    "\n",
    "def calculate_p_beta(name, observable, background):\n",
    "    a, b, loc, scale = beta.fit(background)\n",
    "    p_value = 1-beta.cdf(observable, a, b, loc, scale)\n",
    "    return (name, p_value)\n",
    "\n",
    "def calculate_p_norm(name, observable, background):\n",
    "    mu, std = norm.fit(background.astype('float'))\n",
    "    p_value = 1-norm.cdf(observable, mu, std)\n",
    "    return (name, p_value)\n",
    "\n",
    "def calculate_q(p_table):\n",
    "    q_table = pd.DataFrame(index=p_table.index)\n",
    "    for column in p_table:\n",
    "        no_na_col = p_table[column].dropna()\n",
    "        q_values = pd.DataFrame(fdrcorrection(no_na_col)[1], columns=[column], index=no_na_col.index)\n",
    "        q_table = pd.concat([q_table, q_values], axis=1)\n",
    "    return q_table\n",
    "        \n",
    "def unzip_backgrounds(backgrounds_list):\n",
    "    backgrounds = {}\n",
    "    for df in backgrounds_list:\n",
    "        name = df.columns[0].split('_')[0]\n",
    "        background = []\n",
    "        for column in df.columns:\n",
    "            background = background + df[df[column]>0][column].to_list()\n",
    "        backgrounds[name] = background\n",
    "    return backgrounds\n",
    "\n",
    "def select_significant_models(p_values, observables_scores):\n",
    "    for key in p_values:\n",
    "        if p_values[key][1] > 0.05:\n",
    "            observables_scores.drop(key, axis=1, inplace=True)\n",
    "    return observables_scores\n",
    "\n",
    "def assemble_backgrounds(poly_obs_scores, sig_perm_scores, poly_perm_scores):\n",
    "    backgrounds = {}\n",
    "    for column in poly_obs_scores.columns:\n",
    "        if column == 'sigmoidal':\n",
    "            backgrounds[column] = sig_perm_scores\n",
    "        else:\n",
    "            backgrounds[column] = poly_perm_scores[column-1]\n",
    "    return backgrounds\n",
    "\n",
    "def get_p_values(poly_obs_scores, backgrounds):\n",
    "    p_value_tables = pd.DataFrame(index=poly_obs_scores.index, columns=poly_obs_scores.columns)\n",
    "    for index, row in poly_obs_scores.iterrows():\n",
    "        for model in row.index:\n",
    "            score = row[model]\n",
    "            background = backgrounds[model].loc[index].dropna()\n",
    "            result = calculate_p_norm(index, score, background)\n",
    "            p_value_tables.loc[result[0], model] = result[1]\n",
    "    return p_value_tables\n",
    "\n",
    "def get_q_values(p_value_tables, poly_obs_scores):\n",
    "    q_value_tables = pd.DataFrame(index=poly_obs_scores.index, columns=poly_obs_scores.columns)\n",
    "    for column in p_value_tables:\n",
    "        q_value_tables[column] = fdrcorrection(p_value_tables[column])[1]\n",
    "    return q_value_tables\n",
    "\n",
    "def classify_genes(observables_scores, permutation_scores, q_values):\n",
    "    columns = []\n",
    "    for column in observables_scores.columns:\n",
    "        columns.append(str(column))\n",
    "    observables_scores.columns = columns\n",
    "    q_values.columns = columns\n",
    "\n",
    "    median_scores = {}\n",
    "    for column in observables_scores:\n",
    "        model_perm_score_table = permutation_scores[column]\n",
    "        scores = []\n",
    "        for run in model_perm_score_table:\n",
    "            scores = scores + list(model_perm_score_table[run])\n",
    "        median_scores[column] = statistics.mean(scores)\n",
    "    \n",
    "    models = {}\n",
    "    for column in q_values:\n",
    "        models[column] = list(q_values[q_values[column]<=0.2].index)\n",
    "\n",
    "    continuous = []\n",
    "    for key in models:\n",
    "        if key != 'sigmoidal':\n",
    "            continuous = continuous + models[key]\n",
    "    continuous = set(continuous)\n",
    "\n",
    "    classification = {}\n",
    "    if 'sigmoidal' in models:\n",
    "        sigmoid = set(models['sigmoidal'])\n",
    "        common = continuous.intersection(sigmoid)\n",
    "        sigmoid = [feature for feature in sigmoid if feature not in common]\n",
    "        continuous = [feature for feature in continuous if feature not in common]\n",
    "        common_scores = observables_scores.loc[common, q_values.columns]\n",
    "        for feature in common:\n",
    "            for key in models:\n",
    "                if not feature in models[key]:\n",
    "                    common_scores.loc[feature, key] = np.nan\n",
    "        for column in common_scores:\n",
    "            common_scores[column] = common_scores[column]/median_scores[column]\n",
    "        max_continuous_score = common_scores.drop('sigmoidal', axis=1).idxmax(axis=1)\n",
    "\n",
    "        for index, row in common_scores.iterrows():\n",
    "            dcont = common_scores.loc[index,max_continuous_score.loc[index]]\n",
    "            dsig = common_scores.loc[index,'sigmoidal']\n",
    "            diff = abs(dcont - dsig)\n",
    "            ratio = diff/max([dcont, dsig])*100\n",
    "            common_scores.loc[index, 'c\\s'] = ratio\n",
    "\n",
    "        classification['discarded'] = list(common_scores[common_scores['c\\s']<5].index)\n",
    "\n",
    "        common_scores.drop(classification['discarded'], axis=0, inplace=True)\n",
    "        best_models = pd.DataFrame(common_scores[q_values.columns].astype('float').idxmax(axis=1), columns=['model'])\n",
    "        for index, row in best_models.iterrows():\n",
    "            if row['model'] == 'sigmoidal':\n",
    "                sigmoid.append(index)\n",
    "            else:\n",
    "                continuous.append(index)\n",
    "        classification['sigmoid'] = sigmoid\n",
    "    classification['continuous'] = continuous\n",
    "    return classification\n",
    "\n",
    "def classify_genes_by_q(observables_scores, permutation_scores, q_values):\n",
    "    columns = []\n",
    "    for column in observables_scores.columns:\n",
    "        columns.append(str(column))\n",
    "    observables_scores.columns = columns\n",
    "    q_values.columns = columns\n",
    "\n",
    "    median_scores = {}\n",
    "    for column in observables_scores:\n",
    "        model_perm_score_table = permutation_scores[column]\n",
    "        scores = []\n",
    "        for run in model_perm_score_table:\n",
    "            scores = scores + list(model_perm_score_table[run])\n",
    "        median_scores[column] = statistics.mean(scores)\n",
    "    \n",
    "    models = {}\n",
    "    for column in q_values:\n",
    "        models[column] = list(q_values[q_values[column]<=0.2].index)\n",
    "\n",
    "    continuous = []\n",
    "    for key in models:\n",
    "        if key != 'sigmoidal':\n",
    "            continuous = continuous + models[key]\n",
    "    continuous = set(continuous)\n",
    "\n",
    "    classification = {}\n",
    "    if 'sigmoidal' in models:\n",
    "        sigmoid = set(models['sigmoidal'])\n",
    "        common = continuous.intersection(sigmoid)\n",
    "        sigmoid = [feature for feature in sigmoid if feature not in common]\n",
    "        continuous = [feature for feature in continuous if feature not in common]\n",
    "        common_scores = observables_scores.loc[common, q_values.columns]\n",
    "        for feature in common:\n",
    "            for key in models:\n",
    "                if not feature in models[key]:\n",
    "                    common_scores.loc[feature, key] = np.nan\n",
    "        for column in common_scores:\n",
    "            common_scores[column] = common_scores[column]/median_scores[column]\n",
    "        max_continuous_score = common_scores.drop('sigmoidal', axis=1).idxmax(axis=1)\n",
    "\n",
    "        for index, row in common_scores.iterrows():\n",
    "            dcont = common_scores.loc[index,max_continuous_score.loc[index]]\n",
    "            dsig = common_scores.loc[index,'sigmoidal']\n",
    "            diff = abs(dcont - dsig)\n",
    "            ratio = diff/max([dcont, dsig])*100\n",
    "            common_scores.loc[index, 'c\\s'] = ratio\n",
    "\n",
    "        classification['discarded'] = list(common_scores[common_scores['c\\s']<5].index)\n",
    "\n",
    "        common_scores.drop(classification['discarded'], axis=0, inplace=True)\n",
    "        common_qs = common_scores.index\n",
    "        best_models = pd.DataFrame(q_values.loc[common_qs].astype('float').idxmin(axis=1), columns=['model'])\n",
    "        for index, row in best_models.iterrows():\n",
    "            if row['model'] == 'sigmoidal':\n",
    "                sigmoid.append(index)\n",
    "            else:\n",
    "                continuous.append(index)\n",
    "        classification['sigmoid'] = sigmoid\n",
    "    classification['continuous'] = continuous\n",
    "    return classification\n",
    "\n",
    "def classify_genes_by_q_alternative(observables_scores, permutation_scores, q_values):\n",
    "    columns = []\n",
    "    for column in observables_scores.columns:\n",
    "        columns.append(str(column))\n",
    "    observables_scores.columns = columns\n",
    "    q_values.columns = columns\n",
    "\n",
    "    models = {}\n",
    "    for column in q_values:\n",
    "        models[column] = list(q_values[q_values[column]<=0.2].index)\n",
    "\n",
    "    continuous = []\n",
    "    for key in models:\n",
    "        if key != 'sigmoidal':\n",
    "            continuous = continuous + models[key]\n",
    "    continuous = set(continuous)\n",
    "\n",
    "    classification = {}\n",
    "    if 'sigmoidal' in models:\n",
    "        sigmoid = set(models['sigmoidal'])\n",
    "        common = continuous.intersection(sigmoid)\n",
    "        sigmoid = [feature for feature in sigmoid if feature not in common]\n",
    "        continuous = [feature for feature in continuous if feature not in common]\n",
    "        common_scores = q_values.loc[common, q_values.columns]\n",
    "        common_scores = common_scores.astype(float)\n",
    "        max_continuous_score = common_scores.drop('sigmoidal', axis=1).idxmin(axis=1)\n",
    "\n",
    "        for index, row in common_scores.iterrows():\n",
    "            dcont = common_scores.loc[index,max_continuous_score.loc[index]]\n",
    "            dsig = common_scores.loc[index,'sigmoidal']\n",
    "            diff = abs(dcont - dsig)\n",
    "            ratio = diff/max([dcont, dsig])*100\n",
    "            common_scores.loc[index, 'c\\s'] = ratio\n",
    "\n",
    "        classification['discarded'] = list(common_scores[common_scores['c\\s']<5].index)\n",
    "        common_scores.drop(classification['discarded'], axis=0, inplace=True)\n",
    "        common_qs = common_scores.index\n",
    "        best_models = pd.DataFrame(q_values.loc[common_qs].astype('float').idxmin(axis=1), columns=['model'])\n",
    "        for index, row in best_models.iterrows():\n",
    "            if row['model'] == 'sigmoidal':\n",
    "                sigmoid.append(index)\n",
    "            else:\n",
    "                continuous.append(index)\n",
    "        classification['sigmoid'] = sigmoid\n",
    "    classification['continuous'] = continuous\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-seattle",
   "metadata": {},
   "source": [
    "# TRANSCRIPTOME PROFILING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protective-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:156: UserWarning: Folder input_data already exist...skipping\n",
      "  warnings.warn(\"Folder input_data already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:162: UserWarning: Folder data_raw already exist...skipping\n",
      "  warnings.warn(\"Folder data_raw already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:168: UserWarning: Folder data_clinical already exist...skipping\n",
      "  warnings.warn(\"Folder data_clinical already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:174: UserWarning: Folder sample_by_section already exist...skipping\n",
      "  warnings.warn(\"Folder sample_by_section already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:180: UserWarning: Folder data_fitting already exist...skipping\n",
      "  warnings.warn(\"Folder data_fitting already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:186: UserWarning: Folder rnd_data_fitting already exist...skipping\n",
      "  warnings.warn(\"Folder rnd_data_fitting already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:192: UserWarning: Folder figures already exist...skipping\n",
      "  warnings.warn(\"Folder figures already exist...skipping\",\n",
      "/home/ieo5417/Documenti/colon_paper/git/notebooks/paper_analysis/../../../git/lib/profile_analysis_class.py:198: UserWarning: Folder output already exist...skipping\n",
      "  warnings.warn(\"Folder output already exist...skipping\",\n"
     ]
    }
   ],
   "source": [
    "# Create workflow class, specifying the path to the SETTINGS.ini file\n",
    "pa_transcriptome = ProfileAnalysis('../../../docker/analysis/transcriptome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
